\documentclass[a4paper,10pt,twocolumn]{article}
\usepackage[utf8]{inputenc}

%opening
\title{Filesystem for Job Submission to Grid System}
\author{Josef Kejzlar}

\newcommand{\term}[1]{``#1''}
\newcommand{\code}[1]{``#1''}

\begin{document}

\maketitle

\begin{abstract}
Submitting job to grid system is not an easy task and because there are many different grid software in use, it is hard to find some universal way of submitting user job. Therefore this project tries to introduce user friendly and standardized way of submitting tasks to different grid system using virtual filesystem that acts as a gateway for user. We are trying to minimize necessary user knowledge by exploiting existing Unix standard way of work with virtual filesystem.
\end{abstract}



\section{Introduction}

Submitting a job to grid system is always a little bit tricky, because our executable code and data are transfered to remote location, there run whenever scheduler decides and we have practically no direct control over the process. Yet it is necessary to do some computation in grid system and we have to deal with all obstacles connected with job submission and control.

\subsection{Grid - a wild beast}
Grid system is not something that every researcher can afford to create in his laboratory and these systems are commonly run and administered by IT stuff and not by researches themselves. Therefore there is usually one or two grids available to researcher and he has no way to choose which grid software he will have to deal with. And even though all grid softwares offers some basic common features it is always researcher that has to cope with given grid software feature set and has to adapt program he want to run to the work flow and possibilities of given grid. 

Diversity of grid softwares and necessity to learn new ways of dealing with basic tasks leads to an effort for standardization and unification of access methods to grid system. One result of this effort are libraries trying to offer universal way of accessing grid resources, transparently dealing with differences between grid softwares. Another very common way are standardized interfaces offered directly by grid softwares that can be universally used. Both of these techniques can unfortunately provide access only to the lowest common denominator of features offered by all grid softwares.

Researcher is therefore facing decision whether to fully exploit special features offered by one grid software and be bond to use only this software or to use some generic standardized way and be free to migrate between grids or even use more grids together. We have given ourselves the same question and decided that easy migration, unification and ultimate chance to submit one task to more than one grid is the right way to go. Even though an additional effort is necessary to bend submitted job and submitters work flow to comply with reduced feature set of unified interface.


\subsection{User-friendliness and low barriers}
We would like to bring generic approaches of job submission one step closer to user. It still needs a lot of programming skills to use either generic libraries or unified APIs and there are many caveats caused by complexity of setting up these solutions. We decided to use filesystem as a base interface. Filesystem is one of the best known interfaces that every user has to deal with on daily basis and that proved its quality given the time already in use. Barrier for working with filesystem way of job submission is very low and does not require neither special skills nor special support in tools used by user. Basic file operations can be done in every programming or scripting language and it is possible to do file manipulation even from graphical user interface.

Our basic idea is that user copy all the job files to virtual filesystem and than tell filesystem to submit his job to grid. User is then notified by filesystem that his job has finished and all the results generated during job's life are available again in filesystem. Whole process should be as easy as possible while retaining good configuration and customization of job submission. 

We also does not want to bond one filesystem instance to one grid and therefore we use term \term{service} that represents connection to concrete grid system. Services are configured by administrators and user can choose during job submission which service he wants to use. This way is user completely shielded from problems with grid communication and does not even have to know what grid software he is submitting job to.



\section{Overview}

This section describes what possibilities filesystem offer to user and how the typical job suitable for submission using filesystem should look like.

\subsection{Condor is our inspiration}
While designing how filesystem interface should look like we had to define work flows that we are going to support natively and that would cover with slight modifications as many existing real world scenarios as possible. We did not want to reinvent the wheel because familiarity with interface lower barrier for acceptance of our solution. Therefore we chose Condor grid software as a reference software to support, because Condor, given its long history, could be defined as a base for most of other grid software in use. We also use Condor way of submitting \term{cluster job}. Cluster job contains more instances of program able to be running on multiple nodes in parallel and therefore cluster jobs are also called \term{parallel jobs}. In practice most jobs are cluster jobs, because to fully utilize computing power of grid the task has to run on multiple nodes simultaneously.

\subsection{Typical job}
Typical job suitable for submission using our filesystem has executable that can be run in one or multiple instances. User can define input file, that is passed as standard input. Every instance then produces output file and error file where data from standard output and error streams respectively are stored. Executable can also access other files selected by user during submission that can be modified and will be accessible to user after job finishes. User can also customize executable arguments and environment in which the task is launched.

\subsection{Job parameters}
Each job has several parameters that allows customization of submission. First group of parameters is bond to job executable and specify all the values mentioned above - executable file, input file, output file, error file, command-line arguments and environment variables. Second group of parameters is related to grid system. The most important parameter selects which service to use. Other parameters further customize how executable is going to be run - number of processes in cluster job, memory required by job and so on.

\subsection{Cluster jobs}
To support cluster jobs, filesystem interface has to provide some way how to distinguish instances from each other, because usually each instance need to process different data or do slightly different work. Therefore all executable parameters can contain special string \code{\textdollar(process)} that will be replaced by null based instance index. Using this technique, user can define different input/output/error file for each instance. It is also possible to place instance index into executable arguments or in environment variable. So for example user can define input file name as \code{input\_\textdollar(process).txt} and first instance will get file \code{input\_0.txt} passed in, second \code{input\_1.txt}, third \code{input\_2.txt} and so on. This technique of dealing with different parameters for each instance is very efficient because user does not have to specify unique value for every instance and still has good control over parameter value.



\section{Design}

In this section we discuss how we use files and directories to represent submitted job and how we allow user to interact with filesystem.

\subsection{Virtual filesystem basics}
While designing the filesystem way of submitting job we heavily reused techniques from other virtual filesystems commonly in use. Directories represents some logical objects and creates hierarchical tree structure. Files placed in directories allow read and/or write access to properties of these objects and they are very often created automatically and prefilled with default values, so that user always know what properties object supports and what values these properties holds. By simple reading values from files it is possible to get current value of property and by writing into file the property value is set. Symbolic links are also used to represent relations between objects or properties.


\subsection{Our filesystem structure}
\code{Job} itself is the main object we need to work with. Therefore top-level directories of our filesystem represent jobs and user can create new job by simply creating new directory. Job directory serves as a storage for all necessary files to job submission and its name uniquely identifies job and specify job's name. Every job directory automatically contains some subdirectories and files. In \code{config} subdirectory one can find files representing all configuration parameters. User can modify these files to customize job parameters and each parameter has configurable default value. These values specify for example number of processes, name of executable file, name of input file and so on. Another important subdirectory is \code{data} directory where all user-supplied files are stored. User has to copy at least executable file into data directory and of course all the supplementary files required during job execution should be placed there as well. Last directory is \code{result} directory that holds all the files returned from job execution and is automatically created when job finishes. Result subdirectory is the place where user finds all the created or modified data files as well as error and output files produced during job execution.

Each job directory also contains \term{control} file that allows user to issue commands related to job execution. Control file does not ``remember'' any value and always contains all available commands supported by control file. User can write command into control file and this way trigger action represented by command. Typical example of command is \code{start}, \code{abort} or \code{start\_and\_wait}. For example writing \code{start\_and\_wait} into control file cause current job to be executed and writing does not complete until task finishes. If issued command does not complete successfully, writing returns error. This way we can very easily support waiting for some event without need for polling of status in endless loop and we also handle error state in consistent way. Because querying job status is often necessary and there is also \code{status} file inside job directory. Status file is read only and contains numerical and string representation of job current status.

\subsection{Typical work-flow}
As we already mentioned it is very easy to create new job. User just creates new top-level directory and names it somehow. Immediately after creation job directory already contains all the previously mentioned files and directories.

However it is up to the user to ensure, that each instance writes results to file having unique filename, because during task finishing all the files from all instances are collected in one directory and files having same filename are overwritten in random order.


\end{document}
